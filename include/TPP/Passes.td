//===- TppPasses.td ----------------------------------------*- Tablegen -*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//

#ifndef TPP_DIALECT_TPP_PASSES
#define TPP_DIALECT_TPP_PASSES

include "mlir/Pass/PassBase.td"

def ConvertLinalgToXsmm : Pass<"convert-linalg-to-xsmm", "func::FuncOp"> {
  let summary = "Convert linalg to xsmm";
  let description = [{
    Convert linalg operations to XSMM operations.
  }];
  let dependentDialects = ["func::FuncDialect",
                           "memref::MemRefDialect",
                           "linalg::LinalgDialect",
                           "xsmm::XsmmDialect",
                           "tensor::TensorDialect"];
}

def VerifyXsmmCalls : Pass<"verify-xsmm-calls", "func::FuncOp"> {
  let summary = "Verify XSMM calls (dispatch and invoke)";
  let description = [{
    Make sure XSMM dispatch and invoke call are in a consistent
    state and they do not contradict each others.
  }];
  let dependentDialects = [ "xsmm::XsmmDialect" ];
}

def ConvertLinalgToFunc : Pass<"convert-linalg-to-func", "ModuleOp"> {
  let summary = "Convert linalg to func";
  let description = [{
    Convert linalg named operations to function call using a BLAS-style
    API.
  }];
  let dependentDialects = ["func::FuncDialect",
                           "memref::MemRefDialect",
                           "linalg::LinalgDialect", "LLVM::LLVMDialect"];
}

def ConvertXsmmToFunc : Pass<"convert-xsmm-to-func", "ModuleOp"> {
  let summary = "Convert xsmm to func";
  let description = [{
    Convert XSMM operations to libXSMM function calls.
  }];
  let dependentDialects = ["func::FuncDialect",
                           "memref::MemRefDialect",
                           "xsmm::XsmmDialect",
                           "LLVM::LLVMDialect"];
}

def ConvertCheckToLoops : Pass<"convert-check-to-loops", "func::FuncOp"> {
  let summary = "Convert check to loops";
  let description = [{
    Convert check operations to SCF loops.
  }];
  let dependentDialects = ["scf::SCFDialect"];
}

def ConvertPerfToLoops : Pass<"convert-perf-to-loops", "func::FuncOp"> {
  let summary = "Convert perf to loops";
  let description = [{
    Convert perf operations to SCF loops.
  }];
  let dependentDialects = ["scf::SCFDialect"];
}

def ConvertPerfToFunc : Pass<"convert-perf-to-func", "ModuleOp"> {
  let summary = "Convert perf to func";
  let description = [{
    Convert perf operations to function calls.
  }];
  let dependentDialects = ["func::FuncDialect",
                           "math::MathDialect",
                           "memref::MemRefDialect",
                           "tensor::TensorDialect"];
}

def PackVNNI : Pass<"pack-vnni", "func::FuncOp"> {
  let summary = "Convert matmul/brgemm to vnni layout";
  let description = [{
    Relayout following matmuls and brgemm as following:
    - VNNI Matmul as: C[M][N]= A[M][K] * B[K/VNNI][N][VNNI]
    - VNNI Blocked Matmul as:
      [IB][JB][ib][jb] += [IB][KB][ib][kb] * [JB][KB][kb/VNNI][jb][VNNI]
    - VNNI BRGemm as: C[M][N]= A[R][M][K] * B[R][K/VNNI][N][VNNI]
  }];
  let dependentDialects = ["tensor::TensorDialect"];
}

def PackMatmul : Pass<"pack-matmul", "func::FuncOp"> {
  let summary = "Convert matmul to block layout and back";
  let description = [{
    Block a linalg.matmul
    as: [NB][KB][nb][kb] += [NB][CB][nb][cb] * [KB][CB][cb][kb].
  }];
  let options = [
    ListOption<"blockingFactors", "block-factors", "int64_t",
               "Blocking factor for relayout">
  ];
}

def PackConv2DNchwFchw : Pass<"pack-conv2DNchwFchw", "func::FuncOp"> {
  let summary = "Convert Conv2DNchwFchw to block layout and back";
  let description = [{
    Block Conv2DNchwFchw as: [N][BK][P][Q][bk] += [N][BC][H][W][bc] * [BK][BC][R][S][bk][bc]
                             output            += image             * filter
    Pack the image's channel with a block factor BC.
    Pack the filter's channels C and K with a block factor of BC and BK.
    Pack the output's channel K with a block factor BK.
  }];
  let options = [
    ListOption<"blockingFactors", "block-factors", "int64_t",
               "Blocking factor for relayout">
  ];
}

def PackConv2DNhwcHwcf : Pass<"pack-conv2DNhwcHwcf", "func::FuncOp"> {
  let summary = "Pack and unpack Conv2DNhwcHwcf";
  let description = [{
    Pack Conv2DNhwcHwcf as [N][K'][P][Q][k] += [N][C'][H][W][c] * [K'][C'][R][S][c][k]
                           output           += image            * filter
    Pack the image and block the image's channel with a factor k.
    Pack the filter and block the filter's channels with k and c.
    Pack the output and block the output's channel with k.
  }];
  let options = [
    ListOption<"blockingFactors", "block-factors", "int64_t",
               "Blocking factor for pack and unpack operation">
  ];
}

def TileConsumerAndFuseProducers : Pass<"tile-consumer-and-fuse-producers",
                                        "func::FuncOp"> {
  let summary = "Tile consumers and fuse producers";
  let description = [{
    The pass uses `TileConsumerAndFuseProducersUsingSCFForOp` to tile the
    consumer and fuse the consumer with the producers. The fusion anchor to matmul
    or conv-like patterns allows two additional options to control how many
    producers fuse together with the latched operation and how many consumers.
    Precisely, `max-depth` controls how many producers should be considered, while
    `start-from-last-consumer` allows to move the anchor point to the last fusable
    consumer of the conv or matmul-like pattern.
  }];
  let options = [
    ListOption<"tileSizes", "tile-sizes", "int64_t", "Tile sizes">,
    Option<"maxDepth", "max-depth", "int64_t", "5",
           "Get producers till maxDepth">,
    Option<"numIters", "num-iters", "int64_t", "3",
           "Run fusion for the given number of iterations">,
    Option<"useForAll", "use-for-all", "bool", "true", "Use parallel forAll">,
    Option<"minTileFactor", "min-tile-factor", "int64_t", "2",
           "Minimum factor between dimension size and a tile size">
  ];
  let dependentDialects = ["linalg::LinalgDialect", "scf::SCFDialect",
                           "tensor::TensorDialect"];
}

def LowerPacksAndUnPacks : Pass<"lower-packs-unpacks", "func::FuncOp"> {
  let dependentDialects = ["linalg::LinalgDialect", "scf::SCFDialect",
                           "tensor::TensorDialect"];
}

def RewriteConvToMatmulOrBrgemm : Pass<"rewrite-conv-to-matmul-or-brgemm",
                                       "func::FuncOp"> {
  let summary = "Rewrite Conv2DNhwcHwcfOp/Conv2DNchwFchwOp to Matmul or Brgemm.";
  let description = [{
    Rewrite a convolution to a matmul or brgemm operation.
  }];
  let options = [
    Option<"enableBrgemm", "enable-brgemm", "bool", "false",
           "Rewrite convolution to BRGEMM if possible">
  ];
  let dependentDialects = ["scf::SCFDialect", "linalg::LinalgDialect"];
}

def RewriteMatmulToNestedMatmul : Pass<"rewrite-matmul-to-nested-matmul",
                                       "ModuleOp"> {
  let summary = "Rewrite matmul to parallel and tiled brgemm.";
  let description = [{
    Parallelize and tile the matmul, convert the innertmost matmul to brgemm.
  }];
  let options = [];
  let dependentDialects = ["scf::SCFDialect", "linalg::LinalgDialect", "tensor::TensorDialect"];
}

def RewriteBatchMatmulToMatmul : Pass<"rewrite-batch-matmul-to-matmul",
                                      "func::FuncOp"> {
  let summary = "Rewrite a linalg.batch_matmul to linalg.matmul.";
  let dependentDialects = ["scf::SCFDialect", "linalg::LinalgDialect"];
}

def CombineXsmmOpPass : Pass<"combine-xsmm-op-optimization", "func::FuncOp"> {
  let summary = "Fuse brgemm-add-relu ops into a fused brgemm op";
  let description =
      [{Fuse brgemm-add-relu ops into a fused brgemm op}];

  let dependentDialects = ["xsmm::XsmmDialect"];

}


def DefaultTppPasses : Pass<"default-tpp-passes", "ModuleOp"> {
  let summary = "Collection of default TPP passes";
  let description = [{
    A collection of passes that lower everything TPP-related
    to standard low-level dialects.
  }];
  let options= [
    Option<"linalgToLoops", "linalg-to-loops",
           "bool", /*default=*/"false",
           "Skip all TPP transformations. Lower linalg directly to loops.">,
    ListOption<"parallelTaskGrid", "parallel-task-grid",
           "unsigned", "Grid-sizes for parallel tasks.">

  ];
}

def PropagatePackUnPack : Pass<"propagate-pack-and-unpack", "func::FuncOp"> {
  let summary = "Propagate tensor.pack and tensor.unpack";
  let description = [{
    Attempt to push tensor.pack and tensor.unpack at the boundaries. Currently,
    it propagates through linalg element-wise operations. Only one operand in the
    generic must come from a tensor.pack/tensor.unpack.
  }];
}

def SimplifyAndCanonicalizePack : Pass<"simplify-pack", "func::FuncOp"> {
  let summary = "Simplify and canonicalize tensor.pack";
  let description = [{
    Apply `tensor.pack` and `tensor.unpack` canonicalization and simplification
    patterns.
  }];
}

def ConstantFoldPack : Pass<"constant-fold-pack", "ModuleOp"> {
  let summary = "Constant fold tensor.pack";
  let description = [{
    Reduce pack overhead by folding tensor.pack into constant tensors.
  }];
}

def ElementWiseFusion : Pass<"element-wise-fusion", "func::FuncOp"> {
  let summary = "Run linalg element-wise fusion";
}

def ConvInitSimplify : Pass<"conv-init-simplify", "func::FuncOp"> {
  let summary = "Simplify initialization for convolution";
  let description = [{
    Perform a graph-rewrite to simplify initialization for a Conv2DNhwcHwcfOp
    operation. Specifically, instead of initializing the output of a convolution
    with zero and then adding the bias, initialize the output with the bias.
  }];
}

def Bufferize : Pass<"bufferize", "ModuleOp"> {
  let summary = "Bufferize tensor to memref for the entire module";
  let options = [
    Option<"dealloc", "dealloc", "bool",
            /*default=*/"true",
           "Enables automatic deallocation.">,
    Option<"testAnalysisOnly", "test-analysis-only", "bool",
            /*default=*/"false",
           "Only runs inplaceability analysis (for testing purposes only)">,
    Option<"printConflicts", "print-conflicts", "bool",
            /*default=*/"false",
           "Annotates IR with RaW conflicts. Requires test-analysis-only.">,
    Option<"duplicateFill", "duplicate-fill", "bool",
           /*default=*/"true",
           "Enable duplication of fill operation (for testing only).">
  ];
}

def DuplicateFill : Pass<"duplicate-fill", "func::FuncOp"> {
  let summary = "Duplicate fill operations";
  let description = [{
    Duplicate linalg.fill operations to avoid memref.copy after
    bufferization. This can trigger later folding of the fill.
    We duplicate only zero fill on contraction operations.
  }];
  let dependentDialects = [ "linalg::LinalgDialect" ];
}

def Cleanup : Pass<"cleanup", "func::FuncOp"> {
  let summary = "General IR cleanup e.g., canonicalization, CSE etc.";
}

def LocalDialectsLowering : Pass<"lower-local-dialects", "ModuleOp"> {
  let summary = "Lower all local dialects (XSMM, check etc.).";
  let dependentDialects = ["affine::AffineDialect",
                           "arith::ArithDialect",
                           "func::FuncDialect",
                           "memref::MemRefDialect",
                           "check::CheckDialect",
                           "perf::PerfDialect",
                           "scf::SCFDialect",
                           "tensor::TensorDialect",
                           "xsmm::XsmmDialect",
                           "LLVM::LLVMDialect"];
  let options = [
    ListOption<"parallelTaskGrid", "parallel-task-grid",
           "unsigned", "Grid-sizes for parallel tasks.">

  ];

}

def Postprocessing : Pass<"postprocess", "func::FuncOp"> {
  let summary = "IR postprocessing pass";
  let description = [{
    Apply various postprocessing passes such parallel loop fusion,
    buffer deallocation, general cleanup etc.
  }];
}

def TppMapping : Pass<"tpp-mapping", "ModuleOp"> {
  let summary = "Map operations to be TPP compatible";
  let description = [{
    Apply collection of TPP rewriting passes to map eligble operations
    into equivalent TPP-compatible forms.
  }];
}

def LinalgLowering : Pass<"linalg-lowering", "func::FuncOp"> {
  let summary = "Lower Linalg operations to XSMM operations.";
  let dependentDialects = ["xsmm::XsmmDialect", "scf::SCFDialect",
                           "memref::MemRefDialect"];
}

def ConvertForAllToParallelOp : Pass<"convert-forall-to-parallel",
                                     "func::FuncOp"> {
  let summary = "Convert scf.forall to scf.parallel";
  let description = [{
    Rewrite an scf.forall to scf.parallel after bufferization.
  }];
}

def GpuPipeline : Pass<"gpu-pipeline", "ModuleOp"> {
  let summary = "Lower all eligible operations into GPU compatible IR";
  let options = [
    Option<"gpuBackend", "gpu", "std::string",
            /*default=*/"\"cuda\"",
           "Target GPU backend for lowering (cuda).">,
  ];
}

def GpuConversion : Pass<"gpu-conversion", "ModuleOp"> {
  let summary = "Convert operations to GPU";
  let description = [{
    Convert all eligble operations into generic GPU operations.
  }];
  let options = [
    Option<"useWmma", "wmma",
           "bool", /*default=*/"false",
           "Use WMMA operations">,
    ListOption<"warpTile", "warp-tile", "int64_t", "Warp tile sizes MxNxK">,
  ];
}

def GpuToCuda : Pass<"gpu-to-cuda", "ModuleOp"> {
  let summary = "Lower generic GPU operations to CUDA backend";
  let options = [
    Option<"gpuTriple", "triple", "std::string",
            /*default=*/"\"nvptx64-nvidia-cuda\"",
           "GPU target triple.">,
    Option<"gpuChip", "chip", "std::string",
            /*default=*/"\"sm_70\"",
           "GPU target architecture.">,
    Option<"gpuFeatures", "features", "std::string",
            /*default=*/"\"+ptx60\"",
           "GPU target features.">,
  ];
}

def GpuToVulkan : Pass<"gpu-to-vulkan", "ModuleOp"> {
  let summary = "Lower generic GPU operations to Vulkan backend";
}

def LinalgDeGeneralize : Pass<"linalg-degeneralize-generic-ops", "func::FuncOp"> {
  let summary = "Convert generic ops into named ops";
  let dependentDialects = ["linalg::LinalgDialect"];
}

def DefaultPipeline : Pass<"default-pipeline", "ModuleOp"> {
  let summary = "The default compiler lowering pipeline";
  let description = [{
    A collection of passes that lower everything to MLIR LLVM IR.
  }];
  let options = [
    Option<"gpuBackend", "gpu", "std::string",
            /*default=*/"\"\"",
           "Optional target GPU backend.">,
  ];
}

def SetSPIRVCapabilities : Pass<"set-spirv-capabilities", "ModuleOp"> {
  let summary = "Set SPIR-V capabilities.";
  let options = [
    Option<"clientAPI", "client-api", "std::string",
            /*default=*/"\"vulkan\"",
           "The client API to use for capabilities">,
  ];
}

def SetSPIRVAbiAttribute : Pass<"set-spirv-abi-attr", "gpu::GPUModuleOp"> {
  let summary = "Set SPIR-V ABI attribute.";
  let options = [
    Option<"clientAPI", "client-api", "std::string",
            /*default=*/"\"vulkan\"",
           "The client API to use for ABI attribute">,
  ];
}

def GpuVulkanAbi : Pass<"gpu-vulkan-abi", "ModuleOp"> {
  let summary = "Rewrite GPU kernels to comply with Vulkan ABI.";
  let description = [{
    This pass rewrites GPU kernels and the GPU function launches
    to be compatible with Vulkan calling convention.

    The rewrite is focused only on ensuring GPU kernel prototype
    compatibility with Vulkan ABI.Thus, it is assumed that the kernel
    operations have been already preserved in a separate SPIR-V module.
    The original GPU kernel logic is thrown away to make interface
    adaptation easier.
  }];
  let options = [
    Option<"use64bitIndex", "use-64bit-index",
           "bool", /*default=*/"false",
           "Use 64-bit integers to convert index types">
  ];
}

def DecomposeAggregatedOps : Pass<"decompose-aggregated-ops", "func::FuncOp"> {
  let summary = "Decompose aggregated operations.";
  let description = [{
    Decompose operations that implement the `AggregatedOpInterface`.
  }];
}

def LinalgToGpu : Pass<"linalg-to-gpu", "func::FuncOp"> {
  let summary = "Convert linalg ops to be GPU compatible.";
  let description = [{
    Lower linalg to ops optimized for computation on GPU.
  }];
  let dependentDialects = ["linalg::LinalgDialect",
                           "scf::SCFDialect",
                           "memref::MemRefDialect",
                           "gpu::GPUDialect",
                           "arith::ArithDialect"];
  let options = [
    Option<"useWmma", "wmma",
           "bool", /*default=*/"false",
           "Use WMMA operations">,
    ListOption<"warpTile", "warp-tile", "int64_t", "Warp tile sizes MxNxK">,
    Option<"kTile", "k-tile", "int64_t",
           /*default=*/"32",
           "GEMM tile size for reduction dimension.">,
  ];
}

def GpuDataTransfer : Pass<"gpu-data-transfer", "func::FuncOp"> {
  let summary = "Transfer data to and from GPU.";
  let description = [{
    Make host data required by GPU kernels accessible by the device.
    It might involve data copies and/or movement.
  }];
  let dependentDialects = ["func::FuncDialect",
                           "memref::MemRefDialect",
                           "gpu::GPUDialect"];
}

def FoldXsmmFlags : Pass<"fold-xsmm-flags", "func::FuncOp"> {
  let summary = "Attempt to fold dispatch op as flags in XSMM.";
  let description = [{
    Attempt to fold dispatch operations as flags in consumer dispatch
    operations, for example:
    ```mlir
      %alloc = memref.alloc
      xsmm.unary zero (%alloc)
      xsmm.gemm.dispatch (%alloc)
    ```
    the zero is folded as `beta_0` in `xsmm.gemm.dispatch`.
  }];
  let dependentDialects = [ "memref::MemRefDialect", "xsmm::XsmmDialect" ];
}


def SCFParallelLoopTiling : Pass<"scf-parallel-loop-tiling-pass"> {
  let summary = "Tile parallel loops";
  let options = [
    ListOption<"tileSizes", "parallel-loop-tile-sizes", "unsigned",
               "Factors to tile parallel loops by">,
    Option<"noMinMaxBounds", "no-min-max-bounds", "bool",
           /*default=*/"false",
           "Perform tiling with fixed upper bound with inbound check "
           "inside the internal loops">
  ];
  let dependentDialects = ["affine::AffineDialect", "scf::SCFDialect"];
}

def GpuInlineConstants : Pass<"gpu-inline-constants", "func::FuncOp"> {
  let summary = "Inlines constants into GPU launch.";
  let description = [{
    Inline constants into GPU launch body to reduce number of parameters
    and allow further constant propagation after kernel outlining.
    The pass should be used just before GPU kernel outlining.
  }];
  let dependentDialects = ["gpu::GPUDialect",
                           "arith::ArithDialect"];
}

def IntelAMXTileConfigInsertionPass : Pass<"intel-amx-tile-config-insertion-pass",
                                     "func::FuncOp"> {
  let summary = "Insert intel amx tile configuration xsmm calls";
  let description = [{
    Insert intel amx tile configuration xsmm calls.
  }];

  let dependentDialects = [ "memref::MemRefDialect", "xsmm::XsmmDialect" ];
}

def IntelAMXTileConfigHoistingPass : Pass<"intel-amx-tile-config-hoisting-pass",
                                     "func::FuncOp"> {
  let summary = "Hoist intel amx tile configuration invoke xsmm calls";
  let description = [{
    Run LICM on intel amx tile configuration invoke calls.
  }];

  let dependentDialects = [ "memref::MemRefDialect", "xsmm::XsmmDialect" ];
}

#endif // TPP_DIALECT_TPP_PASSES
